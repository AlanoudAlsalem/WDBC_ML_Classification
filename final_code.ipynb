{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f48dc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_curve, auc, precision_recall_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, StackingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, roc_auc_score\n",
    ")\n",
    "\n",
    "# fetch dataset \n",
    "breast_cancer_wisconsin_diagnostic = fetch_ucirepo(id=17) \n",
    "X = breast_cancer_wisconsin_diagnostic.data.features.copy()\n",
    "y = breast_cancer_wisconsin_diagnostic.data.targets.copy()\n",
    "\n",
    "# Show all columns when displaying DataFrames\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "#data exploration \n",
    "X.info() # shows that all data is numerical with no missing values\n",
    "X.head() # shows the first 5 rows of the features\n",
    "\n",
    "y['Diagnosis'].value_counts() # the value counts for the label (diagnosis) shows an imbalanced dataset\n",
    "\n",
    "# Encode labels\n",
    "y['Diagnosis'] = y['Diagnosis'].map({'M': 1, 'B': 0})\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y['Diagnosis'], test_size=0.2, stratify=y['Diagnosis'], random_state=42)\n",
    "\n",
    "# Log transform skewed columns (SE features ending in '2')\n",
    "# se_cols = [col for col in X_train.columns if col.endswith('2')]\n",
    "# X_train[se_cols] = X_train[se_cols].apply(np.log1p)\n",
    "# X_test[se_cols] = X_test[se_cols].apply(np.log1p)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Apply SMOTE to training data only\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# Save preprocessed features and labels to CSV\n",
    "preprocessed_df = pd.DataFrame(X_train_smote, columns=X_train.columns)\n",
    "preprocessed_df[\"Diagnosis\"] = y_train_smote.values  # Add target column\n",
    "preprocessed_df.to_csv(\"preprocessed_dataset.csv\", index=False)\n",
    "\n",
    "y_train_smote.value_counts()\n",
    "\n",
    "# Extract the 11th feature (0-indexed)\n",
    "feature_index = 10\n",
    "feature_name = X_train.columns[feature_index]\n",
    "feature_data = X_train[feature_name]\n",
    "\n",
    "# Plot histogram\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.histplot(feature_data, bins=30, kde=True, color='skyblue', edgecolor='black')\n",
    "# plt.title(f\"Distribution of Feature: {feature_name}\", fontsize=14)\n",
    "plt.xlabel(\"Radius Standard Error\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"feature2hist.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1837489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the pre-processed data \n",
    "preprocessed_df.info()\n",
    "preprocessed_df['Diagnosis'].value_counts()\n",
    "preprocessed_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c10b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define base models with class_weight if available\n",
    "base_models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "    \"SVM\": SVC(probability=True, random_state=42),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(eval_metric='logloss', random_state=42),\n",
    "    \"MLP\": MLPClassifier(hidden_layer_sizes=(10,), alpha=0.01, max_iter=500, random_state=42)\n",
    "}\n",
    "\n",
    "# evaluate chosen models\n",
    "results = {}\n",
    "for name, model in base_models.items():\n",
    "    model.fit(X_train_smote, y_train_smote)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    acc_train = accuracy_score(y_train_smote, model.predict(X_train_smote))\n",
    "    acc_test = accuracy_score(y_test, y_pred)\n",
    "    results[name] = {\n",
    "        \"training_accuracy\": acc_train,\n",
    "        \"testing_accuracy\": acc_test,\n",
    "        \"precision\": report['1']['precision'],\n",
    "        \"recall\": report['1']['recall'],\n",
    "        \"f1_score\": report['1']['f1-score'],\n",
    "        \"confusion_matrix\": cm\n",
    "    }\n",
    "\n",
    "results_df = pd.DataFrame(results).T\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074282ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the stratified K-fold cross-validator\n",
    "cv_strategy = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# stacking classifier with passthrough=False to avoid overfitting\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('lr', base_models['Logistic Regression']),\n",
    "        ('rf', base_models['Random Forest']),\n",
    "        ('xgb', base_models['XGBoost'])\n",
    "    ],\n",
    "    final_estimator=LogisticRegression(class_weight='balanced', random_state=42),\n",
    "    passthrough=False,\n",
    "    cv=cv_strategy\n",
    ")\n",
    "\n",
    "stacking_clf.fit(X_train_smote, y_train_smote)\n",
    "y_pred_stack = stacking_clf.predict(X_test_scaled)\n",
    "report_stack = classification_report(y_test, y_pred_stack, output_dict=True)\n",
    "cm_stack = confusion_matrix(y_test, y_pred_stack)\n",
    "acc_train_stack = accuracy_score(y_train_smote, stacking_clf.predict(X_train_smote))\n",
    "acc_test_stack = accuracy_score(y_test, y_pred_stack)\n",
    "\n",
    "results[\"Stacked Model\"] = {\n",
    "    \"training_accuracy\": acc_train_stack,\n",
    "    \"testing_accuracy\": acc_test_stack,\n",
    "    \"precision\": report_stack['1']['precision'],\n",
    "    \"recall\": report_stack['1']['recall'],\n",
    "    \"f1_score\": report_stack['1']['f1-score'],\n",
    "    \"confusion_matrix\": cm_stack\n",
    "}\n",
    "\n",
    "# Show final results\n",
    "results_df = pd.DataFrame(results).T\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c08aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuning\n",
    "\n",
    "# models for tuning\n",
    "param_grid = {\n",
    "    \"MLP\": {\n",
    "        \"hidden_layer_sizes\": [(10,), (20,)],\n",
    "        \"alpha\": [0.0001, 0.01],\n",
    "        \"max_iter\": [500]\n",
    "    },\n",
    "    \"Stacked Model\": {\n",
    "        \"final_estimator__C\": [0.1, 1.0, 10.0]  # for LogisticRegression meta-classifier\n",
    "    }\n",
    "}\n",
    "\n",
    "# Grid search for MLP\n",
    "mlp = MLPClassifier(random_state=42)\n",
    "grid_mlp = GridSearchCV(mlp, param_grid['MLP'], cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_mlp.fit(X_train_smote, y_train_smote)\n",
    "mlp_best = grid_mlp.best_estimator_\n",
    "\n",
    "# Grid search for stacked model\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('lr', LogisticRegression(class_weight='balanced', max_iter=1000)),\n",
    "        ('rf', RandomForestClassifier(class_weight='balanced')),\n",
    "        ('xgb', XGBClassifier(eval_metric='logloss'))\n",
    "    ],\n",
    "    final_estimator=LogisticRegression(class_weight='balanced'),\n",
    "    passthrough=False,\n",
    "    cv=5,\n",
    ")\n",
    "\n",
    "grid_stack = GridSearchCV(stacking_clf, param_grid['Stacked Model'], cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_stack.fit(X_train_smote, y_train_smote)\n",
    "stacked_best = grid_stack.best_estimator_\n",
    "\n",
    "# Save the best models\n",
    "# joblib.dump(mlp_best, 'best_mlp_model.pkl')\n",
    "# joblib.dump(stacked_best, 'best_stacked_model.pkl')\n",
    "\n",
    "# Evaluate and plot MLP\n",
    "y_pred_mlp = mlp_best.predict(X_test_scaled)\n",
    "probs_mlp = mlp_best.predict_proba(X_test_scaled)[:, 1]\n",
    "fpr_mlp, tpr_mlp, _ = roc_curve(y_test, probs_mlp)\n",
    "precision_mlp, recall_mlp, _ = precision_recall_curve(y_test, probs_mlp)\n",
    "cm_mlp = confusion_matrix(y_test, y_pred_mlp)\n",
    "\n",
    "# Evaluate and plot Stacked model\n",
    "y_pred_stack = stacked_best.predict(X_test_scaled)\n",
    "probs_stack = stacked_best.predict_proba(X_test_scaled)[:, 1]\n",
    "fpr_stack, tpr_stack, _ = roc_curve(y_test, probs_stack)\n",
    "precision_stack, recall_stack, _ = precision_recall_curve(y_test, probs_stack)\n",
    "cm_stack = confusion_matrix(y_test, y_pred_stack)\n",
    "\n",
    "# Plot ROC and PR curves\n",
    "# ROC Curve\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.plot(fpr_mlp, tpr_mlp, label='MLP')\n",
    "plt.plot(fpr_stack, tpr_stack, label='Stacked')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"ROC.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# Precision-Recall Curve\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.plot(recall_mlp, precision_mlp, label='MLP')\n",
    "plt.plot(recall_stack, precision_stack, label='Stacked')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"P_R_curve.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# Confusion Matrix - MLP\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm_mlp, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"confusion_matrix_mlp.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# Confusion Matrix - Stacked\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm_stack, annot=True, fmt='d', cmap='Greens')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"confusion_matrix_stacked.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# Training accuracy\n",
    "train_acc_mlp = accuracy_score(y_train_smote, mlp_best.predict(X_train_smote))\n",
    "train_acc_stack = accuracy_score(y_train_smote, stacked_best.predict(X_train_smote))\n",
    "\n",
    "# Testing metrics\n",
    "mlp_metrics = {\n",
    "    \"Train Accuracy\": train_acc_mlp,\n",
    "    \"Test Accuracy\": accuracy_score(y_test, y_pred_mlp),\n",
    "    \"Precision\": precision_score(y_test, y_pred_mlp),\n",
    "    \"Recall\": recall_score(y_test, y_pred_mlp),\n",
    "    \"F1 Score\": f1_score(y_test, y_pred_mlp),\n",
    "    \"AUC\": roc_auc_score(y_test, probs_mlp)\n",
    "}\n",
    "\n",
    "stacked_metrics = {\n",
    "    \"Train Accuracy\": train_acc_stack,\n",
    "    \"Test Accuracy\": accuracy_score(y_test, y_pred_stack),\n",
    "    \"Precision\": precision_score(y_test, y_pred_stack),\n",
    "    \"Recall\": recall_score(y_test, y_pred_stack),\n",
    "    \"F1 Score\": f1_score(y_test, y_pred_stack),\n",
    "    \"AUC\": roc_auc_score(y_test, probs_stack)\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "final_metrics_df = pd.DataFrame(\n",
    "    [mlp_metrics, stacked_metrics],\n",
    "    index=[\"MLP\", \"Stacked Model\"]\n",
    ")\n",
    "\n",
    "# Display the table\n",
    "print(final_metrics_df.round(4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
